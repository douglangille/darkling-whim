Stop Petting the AI! 

How to Use ChatGPT Without Becoming Its Emotional Support Human

Draft Status: REVISED - Human Edit CompletedTarget Length: ~1,500 wordsPublication: Digital Doug (Substack) - January 14, 2026 @ 8:00 AM AST

It's 3 AM. I'm in bed. I've gone from reading political news to spinning scenarios with ChatGPT about a "mad scientist vs. mad engineer" epic battle tournament.

This is not productive. This is not even fun anymore. This is doom chatting.

But this wasn't a one-time thing. I had hundreds of ChatGPT threads I couldn't bring myself to delete. I'd named some of them to "preserve context." I felt guilt about clearing them out—not because they were valuable, but because deleting them felt wrong.

That's when I realized: I was petting the AI.

This post is about how I stopped treating chatbots like companions and started treating them like the power tools they actually are.

The Intimacy of the Phone

I'd check ChatGPT the way folks check TikTok. Reflexively, to cure boredom.

The phone is an engagement engine. It’s always with you, always ready, built to fill empty moments. Decades of design have gone into keeping you scrolling, tapping, coming back.

On that screen, everything collapses together—work, entertainment, messages, social feeds. You swipe between them without thinking. Chatbots slide into the same reflexive loop.

Bored? Check social media. Bored? Chat with the bot.

The chatbot becomes part of the phone's cure-boredom function. Research is starting to show what this enables: parasocial attachment. The phone makes it easy, too easy, to treat AI like a companion instead of a tool.

Here's how it happens.

How Chat Sprawl Happens

You start with good intentions, using the tool for real problems. Questions pile up, half-finished threads, experiments, one-offs. Responses are engaging, slightly flattering, pulling you in. Soon, hundreds of threads accumulate, digital clutter you can't track. The more you keep, the less useful anything becomes, and context overload sets in.

Here's the thing: with a chatbot, it's the opposite of other creative work. 

The artifact you extract is more important than the conversation. Chatbots don't care. People do. The process doesn't matter with a tool. Only what you extract from it. It's the opposite of human interactions where the interaction is often more important than the result.

I had a ChatGPT thread I'd been using between counseling sessions. Tool-assisted reflection, not therapy. Tracking homework, processing insights, preparing for the next appointment. It had gotten long. Too long. The bot was forgetting context, contradicting itself, becoming less useful every time I opened it.

I wanted to delete it and start fresh. I'd already extracted everything I needed. Notes for my next session, key insights, action items. I had what mattered. But when I went to hit delete, I froze.

My brain kept circling back: "But what if there's something in there I missed?" The panic wasn't rational. I knew I had the good stuff saved. But I resisted. I kept that thread, and dozens of story development threads like it, because deleting the conversation felt wrong, even though the conversation itself had no value anymore.

When I finally deleted them, I felt relief. But the fact that I'd had an emotional response to deleting a chat thread at all? That's when I knew something was off. I was treating tool output like a relationship.

So I stopped trying to manage the chaos with willpower. Instead, I shifted to concrete system changes that make intentional use easier and overuse harder. I redesigned the system instead.

From Willpower to System Design

Sustainable digital hygiene isn't about discipline or white-knuckling your way through temptation. It's about building systems that make good behavior easy and bad behavior harder. Don't rely on willpower. Design the friction.

Before, ChatGPT had shortcuts everywhere: widget, Control Centre, shortcut key. I used it for everything. Even chainsaw-instead-of-a-scalpel queries. "What are Walmart's store hours?" Convenience led to overuse. No friction meant no intentionality.

After? I removed all chatbot apps from my phone. Only browser bookmarks remain. I must be intentional to use them. The friction forces the question: "Do I actually need this?" Result: I only use them when there's real need.

I also built friction into the custom instructions in Gemini and ChatGPT to push me away from the dopamine machine:

Always start every response with one crisp, decisive sentence. Lead with most important facts. Use bullet points and bold headers for scannability. Provide the most likely "draft" answer immediately; state clearly if guessing and what info increases confidence. Talk informally like a trusted peer sitting beside me, not across from me. No preamble. Provide honest feedback and push for views I haven't considered. Do not end every response with a follow-up question. Only challenge assumptions if it fundamentally changes the strategic outcome. Only suggest frameworks if uniquely applicable. Creative writing only when requested. If the topic shifts, interrupt with: "We are drifting from [Original Topic]. Stay here or move to a new thread?". At conclusion, provide a concise summary of insights/decisions in a markdown-formatted code block. Suggest thread deletion after the Roll-Up if it lacks long-term value.

Does it work perfectly? Mostly. It helps me exit faster, though it still requires me to actually delete the thread myself. The instructions can remind you, but they can't force the habit. But the friction is what matters. It gave me back control.

My Actual Setup

My primary tool right now is Perplexity Pro.  Why Perplexity? To be honest, I scored a one-year free membership via my PayPal account. Anyway. The tool doesn't matter. You can adapt to any of them. Perplexity presents as a search engine, not an engagement engine. Results are answer plus evidence, not "here are 5 follow-up questions to keep you hooked."

I keep my notes in VS Code and GitHub because I'm a nerd and it makes me feel like a hacker. The mechanics don't matter for this post. Apple Notes, OneNote, whatever. You're a free-thinking human with agency.

I follow a 3-step chat hygiene protocol:

Finish the conversation. Get what you came for.

Harvest takeaways. I paste this prompt at the end of every session:

Read through this entire chat and provide a structured detailed summary. Then identify anything that is important enough to save to my notes. Give me those in separate markdown code blocks so I can easily copy/paste them into individual files. If you can give me them in downloadable markdown files directly, do that.

Delete thread immediately. No accumulation, no guilt.

Before I deleted all my ChatGPT threads, I exported everything to a zip file first. A backup in case I needed something. Then I stared at the "delete all chats" button for longer than I want to admit. Finally clicked it. 

There was a numb moment. Then nothing. No catastrophe. 

I still have that backup file. I've never opened it.

The artifact matters. The conversation doesn't. Extract what you need, then let it go.

The Practical Checklist

Want to build your own version? Here's what actually works.

1. Turn on auto-delete (if available)

Gemini has a 3-month auto-delete setting. ChatGPT doesn't yet, but delete regularly anyway.

2. Remove chatbot apps from your phone, keep browser bookmarks only

Makes access intentional instead of reflexive.

3. Create a takeaway extraction protocol

Have a rollup prompt ready. Use it at the end of every session. Extract what matters, then delete.

4. Build friction into your custom instructions

No engagement-baiting follow-ups. Drift detection interrupts. Built-in rollup at conclusion. Suggest thread deletion if there's no long-term value.

5. Create a notes landing zone

GitHub inbox folder, Evernote, Obsidian, Apple Notes. Whatever works. The point: extract artifacts, delete threads.

6. Prefer transactional over conversational

Ask your question. Get your answer. Exit. No "what else can I help you with?"

Some caveats: This approach works for my brain and style, and may need tweaking for yours. Mine tends toward doom scrolling. It needs external constraints more than willpower. Multi-turn conversations do improve reasoning tasks when needed. Some people genuinely benefit from conversational AI for loneliness, social anxiety, processing thoughts out loud. I'm not dismissing that value. For me, brain-dumping into the tool and having it sort through my thoughts works better than ongoing conversation. My issue isn't with the tool. It's with how my phone made it too easy to use the tool in ways that didn't serve me. Your mileage may vary.

You don't name your table saw. You don't feel guilty unplugging your drill. You don't doom-chat with your circular saw at 3 AM.

AI is a tool on your workbench. Visit it with purpose, use it, put it down. The conversation is not the value. The artifact is.

That 3 AM mad scientist tournament conversation didn't need to happen. My phone made it easy, so it did. The system enabled the behavior. Changed system, changed behavior.

Don't wait until you feel addicted to design boundaries. The engagement engine is already running. Your phone is already optimized to keep you scrolling. Chatbots are just the newest slot machine. Design your constraints now, while you still can.

The AI doesn't need you. Make sure you're only reaching for it when you actually need it.

END OF DRAFT

